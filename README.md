# Web Scraper

A simple Node.js script to extract all links from a website and save the content into separate files for easy access and management.

## Description

Maintaining context in AI platforms is challenging with documents, PDFs, and websites scattered online. To help with this, we created a simple script that fetches all the links from a provided URL, visits each link, and extracts the content, saving it into separate files.

## Getting Started

### Prerequisites

- Node.js installed on your machine

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/Irys-xyz/link-extractor.git
   ```

2. Navigate to the project directory:
   ```bash
   cd link-extractor
   ```

3. Install the dependencies:
   ```bash
   npm install
   ```

## Usage

Run the script with your URL:

```bash
node extract-links.js
```

The script will fetch all links from the provided URL, visit each link, extract the content, and save it into separate files for easy access.

## Example

Here is a basic example of how to use the script:

1. Open a terminal and navigate to the project directory.
2. Run the script with your desired URL:
   ```bash
   node extract-links.js
   ```
3. The extracted content will be saved into separate files in the project directory.
